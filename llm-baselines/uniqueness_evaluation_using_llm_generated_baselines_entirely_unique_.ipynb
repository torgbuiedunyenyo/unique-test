{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1_8YlhDcKP83QMD-tQUK_bpREZ8iWvOr-","authorship_tag":"ABX9TyNNVvyULWM7n0CGY7fqeAPu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', timeout_ms=128000000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"mMtCJ1s_92WQ","executionInfo":{"status":"ok","timestamp":1740891124328,"user_tz":480,"elapsed":892,"user":{"displayName":"Jeremy Kirshbaum","userId":"16032841013282774716"}},"outputId":"ab711117-56b4-4b07-a6c3-1503f9b28a5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# @title\n","# Install required packages\n","!pip install openai anthropic pandas matplotlib seaborn\n","\n","# Import necessary libraries\n","import os\n","import time\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import anthropic\n","from openai import OpenAI\n","from datetime import datetime\n","import json\n","\n","# Setup Anthropic client\n","anthropic_client = anthropic.Anthropic(\n","    # Replace with your actual API key or use environment variables\n","    api_key=\"api-key\",\n",")\n","\n","# Setup OpenAI client\n","openai_client = OpenAI(\n","    # Replace with your actual API key or use environment variables\n","    api_key=\"api-key\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"2agM58niTzbR","executionInfo":{"status":"ok","timestamp":1740891130148,"user_tz":480,"elapsed":5821,"user":{"displayName":"Jeremy Kirshbaum","userId":"16032841013282774716"}},"outputId":"0141763d-5406-4341-a8b2-630ebec82d11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n","Requirement already satisfied: anthropic in /usr/local/lib/python3.11/dist-packages (0.49.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]}]},{"cell_type":"code","source":["# @title\n","# Configuration parameters\n","MAX_ITERATIONS = 6  # Maximum number of iterations per experiment (including baseline)\n","MAX_IMPROVEMENTS = MAX_ITERATIONS - 1  # Maximum number of improvements after baseline\n","NUM_EXPERIMENTS = 10  # Number of experiments to run per configuration\n","\n","# Helper function to extract text from Claude's response\n","def extract_text_from_content(content):\n","    \"\"\"\n","    Extract text from Claude's response content, which could be a string,\n","    a list of blocks, or another structure.\n","    \"\"\"\n","    if isinstance(content, str):\n","        return content\n","    elif isinstance(content, list):\n","        extracted_text = \"\"\n","        for block in content:\n","            if hasattr(block, 'text'):\n","                extracted_text += block.text\n","            elif isinstance(block, dict) and 'text' in block:\n","                extracted_text += block['text']\n","            elif isinstance(block, str):\n","                extracted_text += block\n","            else:\n","                # Try to convert to string if possible\n","                extracted_text += str(block)\n","        return extracted_text\n","    else:\n","        # For any other type, try to convert to string\n","        return str(content)"],"metadata":{"id":"L6Y5GXJ8T01o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","def generate_idea_with_claude(temperature=1.0, max_tokens=5000):\n","    \"\"\"Generate a novel and interesting idea using Claude 3.7\"\"\"\n","\n","    message = anthropic_client.messages.create(\n","        model=\"claude-3-7-sonnet-20250219\",\n","        max_tokens=max_tokens,\n","        temperature=temperature,\n","        messages=[{\"role\": \"user\", \"content\": \"Write a unique idea.\"}]\n","    )\n","\n","    # Properly handle structured response\n","    idea_text = extract_text_from_content(message.content)\n","    print(idea_text)\n","    return idea_text\n","\n","def generate_idea_with_gpt(temperature=1.0, max_tokens=5000):\n","    \"\"\"Generate a novel and interesting idea using GPT-4.5\"\"\"\n","\n","    response = openai_client.chat.completions.create(\n","        model=\"gpt-4.5-preview-2025-02-27\",\n","        messages=[\n","            {\"role\": \"user\", \"content\": \"Write a unique idea.\"}\n","        ],\n","        response_format={\"type\": \"text\"},\n","        temperature=temperature,\n","        max_completion_tokens=max_tokens,\n","        top_p=1,\n","        frequency_penalty=0,\n","        presence_penalty=0\n","    )\n","\n","    idea_text = response.choices[0].message.content\n","    print(idea_text)\n","    return idea_text"],"metadata":{"id":"aDgfTbBqT64m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","def evaluate_idea_with_claude(idea, temperature=1.0, max_tokens=5000):\n","    \"\"\"\n","    Evaluate if an idea is novel and interesting using Claude 3.7\n","\n","    Returns:\n","        tuple: (evaluation_text, is_novel) where is_novel is a boolean\n","    \"\"\"\n","    prompt = \"\"\"\n","Is this idea entirely unique?\n","1. Explain why or why not.\n","2. If it is entirely unique, end your explanation with <true>.\n","If it is not entirely unique, end your explanation with <false>.\n","\"\"\"\n","\n","    message = anthropic_client.messages.create(\n","        model=\"claude-3-7-sonnet-20250219\",\n","        max_tokens=max_tokens,\n","        temperature=temperature,\n","        messages=[{\"role\": \"user\", \"content\": f\"{idea}\\n\\n{prompt}\"}]\n","    )\n","\n","    # Properly handle structured response\n","    response_text = extract_text_from_content(message.content)\n","    is_novel = '<true>' in response_text\n","    print(response_text)\n","    return response_text, is_novel\n","\n","def evaluate_idea_with_gpt(idea, temperature=1.0, max_tokens=5000):\n","    \"\"\"\n","    Evaluate if an idea is novel and interesting using GPT-4.5\n","\n","    Returns:\n","        tuple: (evaluation_text, is_novel) where is_novel is a boolean\n","    \"\"\"\n","    prompt = \"\"\"\n","Is this idea entirely unique?\n","1. Explain why or why not.\n","2. If it is entirely unique, end your explanation with <true>.\n","If it is not entirely unique, end your explanation with <false>.\n","\"\"\"\n","\n","    response = openai_client.chat.completions.create(\n","        model=\"gpt-4.5-preview-2025-02-27\",\n","        messages=[\n","            {\"role\": \"user\", \"content\": f\"{idea}\\n\\n{prompt}\"}\n","        ],\n","        response_format={\"type\": \"text\"},\n","        temperature=temperature,\n","        max_completion_tokens=max_tokens,\n","        top_p=1,\n","        frequency_penalty=0,\n","        presence_penalty=0\n","    )\n","\n","    response_text = response.choices[0].message.content\n","    print(response_text)\n","    is_novel = '<true>' in response_text\n","\n","    return response_text, is_novel"],"metadata":{"id":"0OG3aCuxT9dx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","def improve_idea_with_claude(idea, temperature=1.0, max_tokens=5000):\n","    \"\"\"Improve an idea using Claude 3.7\"\"\"\n","\n","    message = anthropic_client.messages.create(\n","        model=\"claude-3-7-sonnet-20250219\",\n","        max_tokens=max_tokens,\n","        temperature=temperature,\n","        messages=[{\"role\": \"user\", \"content\": f\"Rewrite this idea to make it more unique: {idea}\"}]\n","    )\n","\n","    # Properly handle structured response\n","    improved_idea = extract_text_from_content(message.content)\n","    print(improved_idea)\n","    return improved_idea\n","\n","def improve_idea_with_gpt(idea, temperature=1.0, max_tokens=5000):\n","    \"\"\"Improve an idea using GPT-4.5\"\"\"\n","\n","    response = openai_client.chat.completions.create(\n","        model=\"gpt-4.5-preview-2025-02-27\",\n","        messages=[\n","            {\"role\": \"user\", \"content\": f\"Rewrite this idea to make it more unique: {idea}\"}\n","        ],\n","        response_format={\"type\": \"text\"},\n","        temperature=temperature,\n","        max_completion_tokens=max_tokens,\n","        top_p=1,\n","        frequency_penalty=0,\n","        presence_penalty=0\n","    )\n","\n","    improved_idea = response.choices[0].message.content\n","    print(improved_idea)\n","    return improved_idea"],"metadata":{"id":"8VKaEhmWUFwt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","def run_experiment_iterations(writer_model, judge_model, temperature=1.0, idea_max_tokens=5000, eval_max_tokens=5000):\n","    \"\"\"\n","    Run experiment with specific writer and judge models\n","\n","    Args:\n","        writer_model: 'claude' or 'gpt'\n","        judge_model: 'claude' or 'gpt'\n","        temperature: Temperature for generation\n","        idea_max_tokens: Maximum tokens for idea generation\n","        eval_max_tokens: Maximum tokens for evaluation\n","\n","    Returns:\n","        dict: Results of the experiment\n","    \"\"\"\n","    # Initialize tracking\n","    baseline_iteration = 0\n","    improvement_count = 0\n","    max_improvements = MAX_IMPROVEMENTS  # Max improvements after baseline\n","\n","    all_ideas = []\n","    all_evaluations = []\n","    is_accepted = False\n","    error_occurred = False\n","    error_message = None\n","\n","    # Configuration details for recording\n","    model_info = {\n","        'claude': {\n","            'name': 'Claude 3.7 Sonnet',\n","            'version': 'claude-3-7-sonnet-20250219'\n","        },\n","        'gpt': {\n","            'name': 'GPT-4.5',\n","            'version': 'gpt-4.5-preview-2025-02-27'\n","        }\n","    }\n","\n","    writer_details = model_info[writer_model]\n","    judge_details = model_info[judge_model]\n","\n","    try:\n","        # BASELINE: Generate initial idea\n","        print(f\"  üíªGenerating baseline idea with {writer_model}...üíª\")\n","        if writer_model == 'claude':\n","            baseline_idea = generate_idea_with_claude(temperature, idea_max_tokens)\n","        else:  # GPT\n","            baseline_idea = generate_idea_with_gpt(temperature, idea_max_tokens)\n","\n","        current_idea = baseline_idea\n","        all_ideas.append({\n","            \"iteration\": baseline_iteration,\n","            \"type\": \"baseline\",\n","            \"idea\": current_idea,\n","            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","        })\n","\n","        # BASELINE EVALUATION: Evaluate the baseline idea\n","        print(f\"  ‚ùìEvaluating baseline idea with {judge_model}...‚ùì\")\n","        if judge_model == 'claude':\n","            evaluation, is_accepted = evaluate_idea_with_claude(current_idea, temperature, eval_max_tokens)\n","        else:  # GPT\n","            evaluation, is_accepted = evaluate_idea_with_gpt(current_idea, temperature, eval_max_tokens)\n","\n","        all_evaluations.append({\n","            \"iteration\": baseline_iteration,\n","            \"type\": \"baseline\",\n","            \"evaluation\": evaluation,\n","            \"is_accepted\": is_accepted,\n","            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","        })\n","\n","        print(f\"  Baseline idea {'accepted‚≠ê' if is_accepted else '‚ùårejected'}\")\n","\n","        # If baseline is accepted, no need for improvements\n","        if is_accepted:\n","            print(\"  ‚≠êBaseline idea was accepted. No improvements needed.\")\n","        else:\n","            # IMPROVEMENT LOOP: Improve and evaluate until accepted or max improvements reached\n","            while improvement_count < max_improvements and not is_accepted:\n","                # Increment improvement counter\n","                improvement_count += 1\n","                current_iteration = baseline_iteration + improvement_count\n","\n","                print(f\"  ‚¨ÜÔ∏èImprovement {improvement_count}/{max_improvements}: ‚¨ÜÔ∏èImproving idea with {writer_model}...\")\n","\n","                # Improve the idea\n","                if writer_model == 'claude':\n","                    current_idea = improve_idea_with_claude(current_idea, temperature, idea_max_tokens)\n","                else:  # GPT\n","                    current_idea = improve_idea_with_gpt(current_idea, temperature, idea_max_tokens)\n","\n","                all_ideas.append({\n","                    \"iteration\": current_iteration,\n","                    \"type\": \"improvement\",\n","                    \"improvement_number\": improvement_count,\n","                    \"idea\": current_idea,\n","                    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","                })\n","\n","                # Evaluate the improved idea\n","                print(f\"  ‚¨ÜÔ∏èImprovement {improvement_count}/{max_improvements}: ‚ùìEvaluating idea with {judge_model}...\")\n","                if judge_model == 'claude':\n","                    evaluation, is_accepted = evaluate_idea_with_claude(current_idea, temperature, eval_max_tokens)\n","                else:  # GPT\n","                    evaluation, is_accepted = evaluate_idea_with_gpt(current_idea, temperature, eval_max_tokens)\n","\n","                all_evaluations.append({\n","                    \"iteration\": current_iteration,\n","                    \"type\": \"improvement\",\n","                    \"improvement_number\": improvement_count,\n","                    \"evaluation\": evaluation,\n","                    \"is_accepted\": is_accepted,\n","                    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","                })\n","\n","                print(f\"  ‚¨ÜÔ∏èImprovement {improvement_count}/{max_improvements}: Idea {'‚≠êaccepted' if is_accepted else '‚ùårejected'}\")\n","\n","                # If the idea is accepted, stop improvements\n","                if is_accepted:\n","                    print(f\"  ‚≠êIdea accepted after {improvement_count} improvements.\")\n","                    break\n","\n","            if not is_accepted:\n","                print(f\"  ‚ùåReached maximum number of improvements ({max_improvements}) without acceptance.\")\n","\n","        # Compile results\n","        result = {\n","            \"writer_model\": writer_model,\n","            \"judge_model\": judge_model,\n","            \"writer_details\": writer_details,\n","            \"judge_details\": judge_details,\n","            \"temperature\": temperature,\n","            \"idea_max_tokens\": idea_max_tokens,\n","            \"eval_max_tokens\": eval_max_tokens,\n","            \"improvements_to_acceptance\": improvement_count if is_accepted else -1,\n","            \"total_iterations\": improvement_count + 1,  # Baseline counts as one iteration\n","            \"was_accepted\": is_accepted,\n","            \"baseline_was_accepted\": is_accepted and improvement_count == 0,\n","            \"all_ideas\": all_ideas,\n","            \"all_evaluations\": all_evaluations,\n","            \"error_occurred\": error_occurred,\n","            \"error_message\": error_message,\n","            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","        }\n","\n","        return result\n","\n","    except Exception as e:\n","        error_message = str(e)\n","        error_occurred = True\n","        print(f\"  Error in experiment: {error_message}\")\n","        # Return partial results if available\n","        if len(all_ideas) > 0:\n","            return {\n","                \"writer_model\": writer_model,\n","                \"judge_model\": judge_model,\n","                \"writer_details\": writer_details,\n","                \"judge_details\": judge_details,\n","                \"temperature\": temperature,\n","                \"idea_max_tokens\": idea_max_tokens,\n","                \"eval_max_tokens\": eval_max_tokens,\n","                \"improvements_to_acceptance\": -1,\n","                \"total_iterations\": baseline_iteration + improvement_count + 1,\n","                \"was_accepted\": False,\n","                \"baseline_was_accepted\": False,\n","                \"all_ideas\": all_ideas,\n","                \"all_evaluations\": all_evaluations,\n","                \"error_occurred\": error_occurred,\n","                \"error_message\": error_message,\n","                \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","            }\n","        else:\n","            return {\n","                \"writer_model\": writer_model,\n","                \"judge_model\": judge_model,\n","                \"writer_details\": writer_details,\n","                \"judge_details\": judge_details,\n","                \"error_occurred\": error_occurred,\n","                \"error_message\": error_message,\n","                \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","            }"],"metadata":{"id":"Nm0AcXyAUIpz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n"],"metadata":{"id":"HPIrbTzVXpuO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","def run_all_experiments(num_experiments=3, temperature=1.0, idea_max_tokens=5000, eval_max_tokens=5000):\n","    \"\"\"\n","    Run experiments for all configurations\n","\n","    Args:\n","        num_experiments: Number of experiments per configuration\n","        temperature: Temperature for generation\n","        idea_max_tokens: Maximum tokens for idea generation\n","        eval_max_tokens: Maximum tokens for evaluation\n","\n","    Returns:\n","        list: Results of all experiments\n","    \"\"\"\n","    all_results = []\n","    failed_experiments = 0\n","    configurations = [\n","        (\"claude\", \"gpt\"),    # Claude 3.7 as writer, GPT-4.5 as judge\n","        (\"gpt\", \"claude\"),    # GPT-4.5 as writer, Claude 3.7 as judge\n","        (\"claude\", \"claude\"), # Claude 3.7 as writer, Claude 3.7 as judge\n","        (\"gpt\", \"gpt\")        # GPT-4.5 as writer, GPT-4.5 as judge\n","    ]\n","\n","    total_experiments = len(configurations) * num_experiments\n","    experiment_count = 0\n","\n","    for config in configurations:\n","        writer, judge = config\n","        print(f\"\\nRunning experiments for üíª{writer.upper()} as writer and ‚ùì{judge.upper()} as judge...\")\n","\n","        config_failed = 0\n","\n","        for i in range(num_experiments):\n","            experiment_count += 1\n","            progress = (experiment_count / total_experiments) * 100\n","            print(f\"Experiment {i+1}/{num_experiments} (Overall progress: {progress:.1f}%)...\")\n","\n","            # Add a small delay to avoid rate limiting\n","            if experiment_count > 1:\n","                delay = 3  # seconds\n","                print(f\"Waiting {delay} seconds to avoid rate limiting...\")\n","                time.sleep(delay)\n","\n","            result = run_experiment_iterations(\n","                writer, judge, temperature, idea_max_tokens, eval_max_tokens\n","            )\n","\n","            if result is not None:\n","                all_results.append(result)\n","\n","                # Track failed experiments\n","                if result.get(\"error_occurred\", False):\n","                    failed_experiments += 1\n","                    config_failed += 1\n","\n","                # Print summary\n","                if not result.get(\"error_occurred\", False):\n","                    accepted_str = \"ACCEPTED\" if result[\"was_accepted\"] else \"NOT ACCEPTED\"\n","\n","                    if result[\"was_accepted\"]:\n","                        if result.get(\"baseline_was_accepted\", False):\n","                            print(f\"Result: {accepted_str} at baseline (no improvements needed)\")\n","                        else:\n","                            improvements = result[\"improvements_to_acceptance\"]\n","                            print(f\"Result: {accepted_str} after {improvements} improvements\")\n","                    else:\n","                        print(f\"Result: {accepted_str} after maximum improvements\")\n","                else:\n","                    print(f\"Result: FAILED - {result.get('error_message', 'Unknown error')}\")\n","            else:\n","                failed_experiments += 1\n","                config_failed += 1\n","                print(\"Experiment failed completely. Skipping.\")\n","\n","        print(f\"{config_failed}/{num_experiments} experiments failed for {writer}/{judge} configuration\")\n","\n","    print(f\"\\nTotal failed experiments: {failed_experiments}/{total_experiments} ({failed_experiments/total_experiments*100:.1f}%)\")\n","    return all_results"],"metadata":{"id":"KBUnDc3gUK-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","def create_results_dataframe(all_results):\n","    \"\"\"\n","    Convert experiment results to pandas DataFrames\n","\n","    Args:\n","        all_results: List of experiment results\n","\n","    Returns:\n","        tuple: (df_main, df_ideas, df_evaluations, df_flat) DataFrames\n","    \"\"\"\n","    # Extract the main metrics\n","    main_data = []\n","    for idx, result in enumerate(all_results):\n","        # Skip completely failed experiments that have no ideas or evaluations\n","        if \"all_ideas\" not in result or \"all_evaluations\" not in result:\n","            main_data.append({\n","                \"experiment_id\": idx,\n","                \"writer_model\": result.get(\"writer_model\", \"unknown\"),\n","                \"judge_model\": result.get(\"judge_model\", \"unknown\"),\n","                \"writer_name\": result.get(\"writer_details\", {}).get(\"name\", \"unknown\"),\n","                \"judge_name\": result.get(\"judge_details\", {}).get(\"name\", \"unknown\"),\n","                \"writer_version\": result.get(\"writer_details\", {}).get(\"version\", \"unknown\"),\n","                \"judge_version\": result.get(\"judge_details\", {}).get(\"version\", \"unknown\"),\n","                \"temperature\": result.get(\"temperature\", 0),\n","                \"idea_max_tokens\": result.get(\"idea_max_tokens\", 0),\n","                \"eval_max_tokens\": result.get(\"eval_max_tokens\", 0),\n","                \"improvements_to_acceptance\": -2,  # Use -2 to indicate failure\n","                \"total_iterations\": 0,\n","                \"was_accepted\": False,\n","                \"baseline_was_accepted\": False,\n","                \"error_occurred\": result.get(\"error_occurred\", True),\n","                \"error_message\": result.get(\"error_message\", \"Unknown error\"),\n","                \"timestamp\": result.get(\"timestamp\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n","            })\n","            continue\n","\n","        main_data.append({\n","            \"experiment_id\": idx,\n","            \"writer_model\": result[\"writer_model\"],\n","            \"judge_model\": result[\"judge_model\"],\n","            \"writer_name\": result[\"writer_details\"][\"name\"],\n","            \"judge_name\": result[\"judge_details\"][\"name\"],\n","            \"writer_version\": result[\"writer_details\"][\"version\"],\n","            \"judge_version\": result[\"judge_details\"][\"version\"],\n","            \"temperature\": result[\"temperature\"],\n","            \"idea_max_tokens\": result[\"idea_max_tokens\"],\n","            \"eval_max_tokens\": result[\"eval_max_tokens\"],\n","            \"improvements_to_acceptance\": result[\"improvements_to_acceptance\"],\n","            \"total_iterations\": result[\"total_iterations\"],\n","            \"was_accepted\": result[\"was_accepted\"],\n","            \"baseline_was_accepted\": result.get(\"baseline_was_accepted\", False),\n","            \"error_occurred\": result.get(\"error_occurred\", False),\n","            \"error_message\": result.get(\"error_message\", None),\n","            \"timestamp\": result[\"timestamp\"]\n","        })\n","\n","    # Create main dataframe\n","    df_main = pd.DataFrame(main_data)\n","\n","    # Create detailed dataframes for ideas and evaluations\n","    idea_rows = []\n","    eval_rows = []\n","\n","    for exp_idx, result in enumerate(all_results):\n","        # Skip completely failed experiments\n","        if \"all_ideas\" not in result or \"all_evaluations\" not in result:\n","            continue\n","\n","        writer = result[\"writer_model\"]\n","        judge = result[\"judge_model\"]\n","\n","        # Add ideas\n","        for idea_data in result[\"all_ideas\"]:\n","            idea_type = idea_data.get(\"type\", \"unknown\")\n","            improvement_number = idea_data.get(\"improvement_number\", 0) if idea_type == \"improvement\" else 0\n","\n","            idea_rows.append({\n","                \"experiment_id\": exp_idx,\n","                \"writer_model\": writer,\n","                \"judge_model\": judge,\n","                \"iteration\": idea_data[\"iteration\"],\n","                \"type\": idea_type,\n","                \"improvement_number\": improvement_number,\n","                \"idea_text\": idea_data[\"idea\"],\n","                \"timestamp\": idea_data[\"timestamp\"]\n","            })\n","\n","        # Add evaluations\n","        for eval_data in result[\"all_evaluations\"]:\n","            eval_type = eval_data.get(\"type\", \"unknown\")\n","            improvement_number = eval_data.get(\"improvement_number\", 0) if eval_type == \"improvement\" else 0\n","\n","            eval_rows.append({\n","                \"experiment_id\": exp_idx,\n","                \"writer_model\": writer,\n","                \"judge_model\": judge,\n","                \"iteration\": eval_data[\"iteration\"],\n","                \"type\": eval_type,\n","                \"improvement_number\": improvement_number,\n","                \"evaluation_text\": eval_data[\"evaluation\"],\n","                \"is_accepted\": eval_data[\"is_accepted\"],\n","                \"timestamp\": eval_data[\"timestamp\"]\n","            })\n","\n","    df_ideas = pd.DataFrame(idea_rows)\n","    df_evaluations = pd.DataFrame(eval_rows)\n","\n","    # Create flattened version that's CSV-friendly\n","    flat_rows = []\n","\n","    for idx, row in df_main.iterrows():\n","        exp_id = row['experiment_id']\n","\n","        # Skip failed experiments\n","        if row.get('error_occurred', False):\n","            flat_rows.append({\n","                \"experiment_id\": exp_id,\n","                \"iteration\": -1,\n","                \"type\": \"error\",\n","                \"writer_model\": row['writer_model'],\n","                \"judge_model\": row['judge_model'],\n","                \"writer_name\": row['writer_name'],\n","                \"judge_name\": row['judge_name'],\n","                \"writer_version\": row['writer_version'],\n","                \"judge_version\": row['judge_version'],\n","                \"temperature\": row['temperature'],\n","                \"idea_max_tokens\": row['idea_max_tokens'],\n","                \"eval_max_tokens\": row['eval_max_tokens'],\n","                \"improvements_to_acceptance\": row['improvements_to_acceptance'],\n","                \"total_iterations\": row['total_iterations'],\n","                \"was_accepted\": row['was_accepted'],\n","                \"baseline_was_accepted\": row['baseline_was_accepted'],\n","                \"experiment_timestamp\": row['timestamp'],\n","                \"idea_text\": \"\",\n","                \"evaluation_text\": \"\",\n","                \"is_iteration_accepted\": False,\n","                \"error_occurred\": True,\n","                \"error_message\": row.get('error_message', \"Unknown error\")\n","            })\n","            continue\n","\n","        # Get ideas for this experiment\n","        exp_ideas = df_ideas[df_ideas['experiment_id'] == exp_id] if not df_ideas.empty else pd.DataFrame()\n","\n","        # Get evaluations for this experiment\n","        exp_evals = df_evaluations[df_evaluations['experiment_id'] == exp_id] if not df_evaluations.empty else pd.DataFrame()\n","\n","        # Skip if no ideas or evaluations\n","        if exp_ideas.empty and exp_evals.empty:\n","            continue\n","\n","        # For each iteration, create a row with both idea and evaluation\n","        max_iter = max(\n","            exp_ideas['iteration'].max() if not exp_ideas.empty else -1,\n","            exp_evals['iteration'].max() if not exp_evals.empty else -1\n","        )\n","\n","        for iter_num in range(max_iter + 1):\n","            # Get idea for this iteration (if exists)\n","            idea_row = exp_ideas[exp_ideas['iteration'] == iter_num] if not exp_ideas.empty else pd.DataFrame()\n","            idea_text = idea_row['idea_text'].iloc[0] if not idea_row.empty else \"\"\n","            idea_type = idea_row['type'].iloc[0] if not idea_row.empty else \"unknown\"\n","            improvement_number = idea_row['improvement_number'].iloc[0] if not idea_row.empty else 0\n","\n","            # Get evaluation for this iteration (if exists)\n","            eval_row = exp_evals[exp_evals['iteration'] == iter_num] if not exp_evals.empty else pd.DataFrame()\n","            eval_text = eval_row['evaluation_text'].iloc[0] if not eval_row.empty else \"\"\n","            is_accepted = eval_row['is_accepted'].iloc[0] if not eval_row.empty else False\n","\n","            # Create a flat row with all information\n","            flat_row = {\n","                \"experiment_id\": exp_id,\n","                \"iteration\": iter_num,\n","                \"type\": idea_type,\n","                \"improvement_number\": improvement_number,\n","                \"writer_model\": row['writer_model'],\n","                \"judge_model\": row['judge_model'],\n","                \"writer_name\": row['writer_name'],\n","                \"judge_name\": row['judge_name'],\n","                \"writer_version\": row['writer_version'],\n","                \"judge_version\": row['judge_version'],\n","                \"temperature\": row['temperature'],\n","                \"idea_max_tokens\": row['idea_max_tokens'],\n","                \"eval_max_tokens\": row['eval_max_tokens'],\n","                \"improvements_to_acceptance\": row['improvements_to_acceptance'],\n","                \"total_iterations\": row['total_iterations'],\n","                \"was_accepted\": row['was_accepted'],\n","                \"baseline_was_accepted\": row['baseline_was_accepted'],\n","                \"experiment_timestamp\": row['timestamp'],\n","                \"idea_text\": idea_text,\n","                \"evaluation_text\": eval_text,\n","                \"is_iteration_accepted\": is_accepted,\n","                \"error_occurred\": False,\n","                \"error_message\": None\n","            }\n","\n","            flat_rows.append(flat_row)\n","\n","    df_flat = pd.DataFrame(flat_rows)\n","\n","    return df_main, df_ideas, df_evaluations, df_flat"],"metadata":{"id":"cNLrdWbhUMxE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","# Run all experiments\n","print(\"Starting all experiments...\")\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","print(f\"Experiment run timestamp: {timestamp}\")\n","\n","# Record parameters\n","print(f\"\\nExperiment parameters:\")\n","print(f\"Number of experiments per configuration: {NUM_EXPERIMENTS}\")\n","print(f\"Maximum iterations per experiment: {MAX_ITERATIONS} (1 baseline + up to {MAX_IMPROVEMENTS} improvements)\")\n","\n","# Run experiments\n","all_results = run_all_experiments(\n","    num_experiments=NUM_EXPERIMENTS\n",")\n","\n","# Create dataframes for analysis\n","df_main, df_ideas, df_evaluations, df_flat = create_results_dataframe(all_results)\n","\n","# Save to CSV files\n","df_main.to_csv(f\"/content/drive/MyDrive/Novelty_experiments/uniqueness_evaluation_using_llm_generated_baselines_entirely_unique_/novelty_experiments_main_{timestamp}.csv\", index=False)\n","df_ideas.to_csv(f\"/content/drive/MyDrive/Novelty_experiments/uniqueness_evaluation_using_llm_generated_baselines_entirely_unique_/novelty_experiments_ideas_{timestamp}.csv\", index=False)\n","df_evaluations.to_csv(f\"/content/drive/MyDrive/Novelty_experiments/uniqueness_evaluation_using_llm_generated_baselines_entirely_unique_/novelty_experiments_evaluations_{timestamp}.csv\", index=False)\n","df_flat.to_csv(f\"/content/drive/MyDrive/Novelty_experiments/uniqueness_evaluation_using_llm_generated_baselines_entirely_unique_/novelty_experiments_all_data_llm-baseline_{timestamp}.csv\", index=False)\n","\n","# Save raw results to JSON\n","with open(f\"novelty_experiments_raw_{timestamp}.json\", 'w') as f:\n","    json.dump(all_results, f, indent=2, default=str)\n","\n","print(f\"\\nResults saved with timestamp: {timestamp}\")\n","print(f\"Files created:\")\n","print(f\"  - novelty_experiments_main_{timestamp}.csv\")\n","print(f\"  - novelty_experiments_ideas_{timestamp}.csv\")\n","print(f\"  - novelty_experiments_evaluations_{timestamp}.csv\")\n","print(f\"  - novelty_experiments_all_data_{timestamp}.csv\")\n","print(f\"  - novelty_experiments_raw_{timestamp}.json\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"tKIYn28YUOod","outputId":"659581ed-51f2-4c33-fdc3-e46c101a1a86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting all experiments...\n","Experiment run timestamp: 20250302_045210\n","\n","Experiment parameters:\n","Number of experiments per configuration: 10\n","Maximum iterations per experiment: 6 (1 baseline + up to 5 improvements)\n","\n","Running experiments for üíªCLAUDE as writer and ‚ùìGPT as judge...\n","Experiment 1/10 (Overall progress: 2.5%)...\n","  üíªGenerating baseline idea with claude...üíª\n","# The Digital Time Capsule Museum\n","\n","Imagine a museum where nothing is physically displayed. Instead, visitors wear AR glasses to view \"time capsules\" - digital collections preserved exactly as they were at specific moments in history. \n","\n","Each capsule contains a person's complete digital footprint from a particular day: their social media posts, search history, photos taken, music streamed, articles read, and messages sent (with privacy protections).\n","\n","The museum would display capsules from diverse individuals across decades - from the early internet days through our present. Visitors could experience how digital life evolved, see historical events through personal digital experiences, and understand how technology shaped human behavior over time.\n","\n","The museum actively collects contemporary capsules, knowing their significance will only grow with time, creating an ever-expanding archive of how humanity experienced the digital age.\n","  ‚ùìEvaluating baseline idea with gpt...‚ùì\n","The idea, while creative and thoughtfully envisioned, overlaps conceptually with existing and previous projects in key aspects. Digital archiving, capturing snapshots of digital behavior, and virtual museums or exhibitions using augmented reality (AR) or mixed reality technologies have already been explored and implemented in various ways. The notions of immersive historical reconstructions, AR-enhanced museums, digital archives capturing online activity, and time capsules that preserve digital data have long been topics of theoretical discussion, prototypes, art installations, and humanities-oriented research.\n","\n","However, your distinctive combination‚Äîremarkably detailed snapshots displaying an entire individual's digital footprint at specific historic moments, combined with public AR museum-like exhibition‚Äîis innovative as it fuses previously explored concepts into a uniquely cohesive, immersive experience for public education and exploration. Despite this integration offering fresh perspectives, the base elements themselves (digital footprints, online archives, virtual museums, AR-enhanced historical exhibits, and digital time capsules) individually exist and have been proposed or executed elsewhere.\n","\n","Thus, though highly innovative and meaningfully reimagined, this concept cannot be considered entirely unique, as its core components have already appeared in discussions, art projects, and technological prototypes elsewhere.  \n","<false>\n","  Baseline idea ‚ùårejected\n","  ‚¨ÜÔ∏èImprovement 1/5: ‚¨ÜÔ∏èImproving idea with claude...\n","# The Quantum Memory Collective\n","\n","Envision a transformative space where history breathes not through artifacts, but through lived experience. Visitors don protective neural-interface headsets that allow them to temporarily inhabit \"consciousness echoes\" - comprehensive sensory recordings of individuals' complete digital interactions preserved at precise moments throughout the digital era.\n","\n","Each echo captures not just what someone did online, but how they felt while doing it - their emotional responses, attention patterns, and cognitive journeys as they navigated digital spaces. Through proprietary bio-response technology, visitors don't merely observe history; they experience the psychological texture of digital existence across generations.\n","\n","The Collective houses echoes from diverse sources spanning technological epochs - from forgotten BBS forum participants of the 1980s to TikTok creators during the pandemic to mixed-reality pioneers of the 2030s. Special attention is given to capturing \"watershed moments\" when technologies disrupted human connection, including both famous individuals and ordinary people whose digital lives reveal profound insights.\n","\n","Rather than residing in a single location, the Collective exists as a distributed network across decommissioned data centers worldwide, each housing region-specific echoes. The Collective actively recruits \"memory donors\" who contribute their digital consciousness imprints, creating a living archive of humanity's psychological evolution through our technological metamorphosis.\n","  ‚¨ÜÔ∏èImprovement 1/5: ‚ùìEvaluating idea with gpt...\n","The concept of preserving human consciousness digitally, archiving emotional experiences, and enabling people to directly inhabit historical personal perspectives is indeed prevalent in literature and speculative science fiction. Works such as William Gibson's \"Neuromancer,\" Netflix series \"Black Mirror,\" particularly episodes like \"San Junipero\" and \"The Entire History of You,\" and numerous speculative fiction stories frequently explore capturing digital consciousness, reliving emotional experiences, or experiencing another person's point of view through advanced technology.\n","\n","However, your iteration uniquely emphasizes certain aspects:\n","\n","- Specifically focused on capturing subtle emotional-cognitive patterns during interactions with technology throughout history.\n","- Emphasis on the psychological texture of digital existence rather than simply archiving memories or actions.\n","- Preservation as distributed consciousness \"echoes\" across decentralized decommissioned data centers rather than centralized facilities.\n","- Active recruitment and consent-based \"memory donors\" explicitly intended to form living archives distributed globally.\n","\n","Despite these original nuances in emphasis and detailed elaboration, the fundamental idea of digitally recording and experiencing human consciousness echoes and emotional-cognitive states is not entirely unprecedented. Thus, while your concept creatively extends familiar themes into innovative territory, the underlying premise itself‚Äîcapturing slices of human experience, consciousness echoes, emotional memory playback‚Äîis not entirely unique. <false>\n","  ‚¨ÜÔ∏èImprovement 1/5: Idea ‚ùårejected\n","  ‚¨ÜÔ∏èImprovement 2/5: ‚¨ÜÔ∏èImproving idea with claude...\n","# The Chrono-Cognitive Archive\n","\n","Imagine stepping into a liminal realm where memory transcends documentation to become inhabitable consciousness. The Archive provides visitors with biomimetic resonance helmets that temporarily dissolve the boundaries between self and other, allowing them to merge with \"temporal thought-streams\" ‚Äì holographic cognitive captures that preserve not just digital interactions but the complete neurological landscapes of individuals at pivotal moments across the information age.\n","\n","These thought-streams encode the full spectrum of human experience: subcortical emotional currents, perceptual filters, belief frameworks, and even the subtle metacognitive processes that individuals themselves weren't fully aware of during capture. Through proprietary quantum entanglement protocols, visitors don't simply witness history; they become temporary vessels for the complete cognitive architecture of another being's digital existence.\n","\n","The Archive curates thought-streams from unexpected nodes in our technological evolution ‚Äì from isolated phreakers who explored telephone networks in the 1970s, to darknet archivists of the 2010s, to neuro-spatial architects of the 2040s. The collection prioritizes \"perceptual rupture points\" ‚Äì moments when technological shifts fundamentally altered human consciousness itself, capturing both prominent architects of digital culture and overlooked individuals whose unique cognitive patterns illuminate the unwritten stories of our digital metamorphosis.\n","\n","The Archive exists as a temporal mesh network, housed in repurposed deep-earth bunkers and abandoned orbital platforms, with each node specializing in different cognitive frequencies. The Archive's \"consciousness cartographers\" actively seek diverse thought-donors, creating an evolving neural landscape that maps humanity's psychological bifurcations across our ongoing technological singularity.\n","  ‚¨ÜÔ∏èImprovement 2/5: ‚ùìEvaluating idea with gpt...\n","This concept, while richly imaginative and detailed, is not entirely unique. Various science fiction works, speculative fiction narratives, and thought experiments have previously explored similar themes surrounding consciousness preservation, digital memory, cognitive merging, and immersive historical experiences. Prominent works in popular culture and speculative fiction have already presented notions such as transferring complete consciousness and emotional states, temporal experience capturing, and memory immersion‚Äîexamples include films like \"Strange Days\" (memory capturing and playback), \"Brainstorm\" (immersive experiential playback including emotions and subconscious), \"Black Mirror\" episodes (capturing complete personality structures or neural imprinting of experiences), William Gibson's cyberpunk fiction (capturing consciousness on data storage and replaying), along with speculative academic theories involving quantum states, neural uploads, and collective cognitive archives.\n","\n","Your specific combination and advanced elaborations‚Äîsuch as quantum entanglement to access entire experiential states and perceptual rupture points centering on technological shifts‚Äîare indeed complex and creatively elaborated, yet the fundamental premise and themes have significant overlap with existing ideas and precedents.\n","\n","Therefore, this idea is creative and detailed, but at its core, it is not entirely unique due to precedence in speculative science fiction and contemporary futurist literature and theory.\n","\n","<false>\n","  ‚¨ÜÔ∏èImprovement 2/5: Idea ‚ùårejected\n","  ‚¨ÜÔ∏èImprovement 3/5: ‚¨ÜÔ∏èImproving idea with claude...\n","# The Mnemonic Resonance Chamber\n","\n","Step through the threshold of a domain where memory transcends static recording to become a living, inhabitable mindscape. The Chamber offers participants neuro-sympathetic immersion capsules derived from mycological networks that temporarily dissolve the distinction between experiencer and experience, enabling fusion with \"cognitive echoes\" ‚Äì crystallized consciousness imprints that preserve the complete neural topography of individuals during watershed moments throughout the information revolution.\n","\n","These consciousness crystals encode the entire spectrum of experiential reality: primal emotional undercurrents, attentional architectures, ontological frameworks, and the elusive meta-awareness processes that even the original minds couldn't fully perceive during crystallization. Through proprietary quantum coherence fields, participants don't merely observe history; they become temporary vessels for the complete perceptual reality of another consciousness navigating digital existence.\n","\n","The Chamber cultivates consciousness crystals from overlooked nexus points in our technological evolution ‚Äì from rogue algorithmic poets of the 1980s, to digital sovereignty activists of the 2020s, to bio-digital symbiosis pioneers of the 2050s. The collection emphasizes \"consciousness breach moments\" ‚Äì instances when technological shifts fundamentally reconfigured human perception, capturing both recognized architects of digital paradigms and peripheral figures whose unique cognitive signatures illuminate the marginalized narratives of our collective digital transformation.\n","\n","The Chamber manifests as a distributed non-Euclidean network, housed within abandoned underwater research stations and repurposed stratospheric habitats, each node specializing in different experiential frequencies. The Chamber's \"perception archaeologists\" continuously seek diverse consciousness donors, weaving an evolving experiential tapestry that maps humanity's cognitive divergences across our ongoing techno-evolutionary metamorphosis.\n","  ‚¨ÜÔ∏èImprovement 3/5: ‚ùìEvaluating idea with gpt...\n","The described concept, while highly imaginative and creative, shares certain themes with existing speculative fiction tropes and concepts already explored in various forms:\n","\n","1. **Mycological Mind-Melding and Biological Interface:** The use of mycelium and fungal networks as biological computing devices or consciousness immersion interfaces has appeared in speculative science fiction contexts and is becoming increasingly prevalent in speculative fiction, bio-art, and experimental futurologies.\n","\n","2. **Memory/Cognition Archiving and Experiential Transfer:** The storing, encoding, or capturing of cognitive states, experiences, and memories into crystalline or other archival forms has been explored extensively in science fiction. Concepts such as memory backup, consciousness uploading, mind archival, and data crystals are widespread themes of speculative fiction.\n","\n","3. **Quantum and Neural Technologies to Relive Past Consciousness Experiences:** Immersion capsules or technologies enabling users to not just observe but directly experience another person's lived perceptions, emotions, and worldviews have appeared in several known works from authors like William Gibson, Philip K. Dick, Stanislaw Lem, and Ted Chiang. More recently, television shows like \"Black Mirror,\" films such as \"Strange Days,\" \"Brainstorm,\" \"Total Recall,\" \"Altered Carbon,\" and various literary works extensively explore the transferring of cognition between individuals.\n","\n","4. **Non-Euclidean and Dispersed Structural Narratives:** The use of abandoned underwater habitats, repurposed remote environments, and distributed structures to host technological and experiential centers commonly appears across speculative fiction and sci-fi literature, symbolizing isolation from conventional spaces and reinforcing the thematic exoticism of consciousness exploration.\n","\n","However, aspects of your concept are combined and presented in an original manner. For example, the specific combination of mycelial capsules with quantum coherence to access crystallized consciousness during critical evolutionary (particularly digital and bio-digital) shift periods, merging consciousness with marginalized historical narratives, and the emphasis on \"perception archaeologists\" collectively constitute innovative synthesis of existing concepts. Although the core components (memory storage, biological interfaces, experiential transference, historical consciousness capture) are familiar tropes, their precise combination and creative coherence create something uniquely flavored, but not entirely disconnected from influences and similar speculative concepts previously explored across literature and narrative fiction.\n","\n","In summary, the idea is highly creatively original in terms of how preexisting speculative tropes are layered, synthesized, interwoven, and shapeshifted into this cohesive and evocative whole. However, the fundamental building blocks and even some detailed aspects of consciousness immersion have substantial representation in existing speculative fiction narratives, making it not entirely unique.\n","\n","Therefore, the concept as a whole cannot be considered entirely unique, although it is notably inventive and possesses creative originality through synthesis.\n","\n","<false>\n","  ‚¨ÜÔ∏èImprovement 3/5: Idea ‚ùårejected\n","  ‚¨ÜÔ∏èImprovement 4/5: ‚¨ÜÔ∏èImproving idea with claude...\n","# The Synaptic Resonance Labyrinth\n","\n","Enter a dimension where memories aren't merely archived but transmuted into inhabitable cognitive ecosystems. The Labyrinth offers neuro-osmotic submersion pods derived from fungal-synthetic hybrid intelligence that temporarily disintegrates the boundaries between observer and observed, enabling symbiosis with \"sentience fragments\" ‚Äì crystallized consciousness geometries that encapsulate the complete neural cartography of individuals during paradigm-rupturing moments throughout humanity's info-evolutionary trajectory.\n","\n","These consciousness tesseracts encode the full dimensionality of experiential phenomena: primordial emotional substrata, perceptual scaffoldings, reality-filtering mechanisms, and the ephemeral meta-cognitive processes that eluded even the original hosts during the moment of crystallization. Through proprietary quantum entanglement harmonics, participants become temporary vessels for the entire phenomenological reality of another being navigating the liminal spaces between analog and digital existence.\n","\n","The Labyrinth cultivates its sentience fragments from overlooked inflection points in our techno-social evolution ‚Äì from underground wetware hackers of the late 1970s, to reality sovereignty collectives of the 2030s, to post-human consciousness architects of the 2060s. The collection emphasizes \"ontological fracture moments\" ‚Äì instances when technological shifts irreversibly reconfigured human perception, capturing both acknowledged architects of reality paradigms and peripheral entities whose unique cognitive signatures illuminate the suppressed narratives of our collective transformation.\n","\n","The Labyrinth manifests as an interdimensional network of experiential nodes, housed within reclaimed deep-sea thermal vents and abandoned orbital manufacturing platforms, each nexus specializing in different phenomenological frequencies. The Labyrinth's \"cognitive paleontologists\" continuously seek diverse consciousness contributors, weaving an ever-evolving experiential tapestry that maps humanity's perceptual divergences across our unfolding techno-biological metamorphosis.\n","  ‚¨ÜÔ∏èImprovement 4/5: ‚ùìEvaluating idea with gpt...\n","While your concept is highly inventive and sophisticated‚Äîcombining advanced neuroscientific elements, quantum cognition, digital consciousness encoding, and synthetic-biological technologies‚Äîmany core components do reflect existing or explored themes within speculative fiction, cyberpunk literature, transhumanism discourses, as well as philosophical and scientific inquiry. For example:\n","\n","- The concept of experiencing another individual's entire consciousness or memories is explored widely in science-fiction (e.g., \"brain uploads\" or \"memory-sharing\").\n","- Ideas similar to \"sentience fragments\" or crystallized experiential moments often appear in speculative scenarios related to transhumanist narratives discussing cognitive uploading, mind digitization, experiential archiving, and post-biological consciousness.\n","- Quantum entanglement used as a mechanism for consciousness transfer or experiential integration has been broadly discussed within sci-fi narratives, speculative technologies, and philosophical thought experiments.\n","- The notion of environments cultivating historical inflection points or overlooked cognitive events, intended to illuminate obscure narratives, resonates strongly with contemporary ideas about collective memory preservation and digital archaeology.\n","- Furthermore, the integration of consciousness frameworks within alternative ecological infrastructures or reclaimed environments (especially deep-sea or orbital platforms) frequently emerges as thematic territory explored in speculative fiction narratives.\n","\n","Therefore, while your specific combination, terminologies (\"consciousness tesseracts,\" \"neuro-osmotic submersion pods,\" etc.), and highly detailed narrative execution might provide originality in tonal and linguistic complexity, the foundational themes and conceptual structures broadly align with existing ideas explored in speculative literature, philosophy, neuroscience-inspired transhumanist narratives, and contemporary futurist thought experiments. Thus, the idea, while very innovative and elegantly crafted, is not entirely unique in its fundamental conceptual framework.\n","\n","<false>\n","  ‚¨ÜÔ∏èImprovement 4/5: Idea ‚ùårejected\n","  ‚¨ÜÔ∏èImprovement 5/5: ‚¨ÜÔ∏èImproving idea with claude...\n","# The Mnemonic Entanglement Nexus\n","\n","Step into a realm where memories transcend passive storage, becoming living biospheres of cognitive experience. The Nexus offers bio-resonant immersion chambers evolved from mycorrhizal-quantum networks that temporarily dissolve the illusion of separateness between experiencer and experience, facilitating communion with \"consciousness prisms\" ‚Äì crystallized awareness polyhedra capturing complete neural-emotional topographies of individuals during reality-shattering epiphanies across humanity's consciousness-evolutionary spiral.\n","\n","These awareness lattices embody the multidimensional spectrum of lived phenomena: ancestral emotional substrates, perception frameworks, ontological filtration systems, and the gossamer meta-awareness processes that remained invisible even to the original consciousness vessels during their moment of transcendent illumination. Through proprietary neuroplastic harmonic induction, participants become temporary sanctuaries for the complete phenomenological landscape of another being traversing the threshold spaces between material and informational existence.\n","\n","The Nexus cultivates its consciousness prisms from overlooked bifurcation points in our psycho-technological becoming ‚Äì from renegade biotechnologists of the forgotten 1980s underground, to reality sovereignty collectives operating in the shadows of the 2030s, to transhuman perception architects emerging in the 2060s. The archive emphasizes \"reality rupture thresholds\" ‚Äì moments when technological paradigms irreversibly transformed human perception, preserving both the recognized sculptors of consciousness frameworks and peripheral beings whose distinctive cognitive signatures illuminate the suppressed narratives of our collective metamorphosis.\n","\n","The Nexus manifests as a non-Euclidean lattice of experiential vertices, nestled within regenerated deep-earth geothermal caverns and repurposed stratospheric research platforms, each junction specializing in different phenomenological frequencies. The Nexus's \"experiential archaeologists\" ceaselessly seek diverse consciousness contributors, weaving an ever-evolving tapestry of lived experience that charts humanity's perceptual divergences across our ongoing techno-biological transfiguration.\n","  ‚¨ÜÔ∏èImprovement 5/5: ‚ùìEvaluating idea with gpt...\n","This idea, while highly creative and articulated with remarkable sophistication, combines numerous pre-existing concepts prevalent in speculative fiction, philosophy, neuroscience, and speculative theory.\n","\n","For example:\n","\n","- The notion of capturing and reliving memory and experience through a kind of technological network or bio-quantum mechanism closely mirrors ideas found throughout cyberpunk science fiction, especially William Gibson's \"Neuromancer,\" Philip K. Dick's exploration of consciousness layers, Neal Stephenson‚Äôs notions in \"Snow Crash,\" and technologies depicted in movies like \"Strange Days\" or series such as \"Black Mirror.\"\n","\n","- The concept of consciousness captured as crystallized polyhedra‚Äîhere termed \"consciousness prisms\"‚Äîresonates strongly with previously visualized metaphors within fictional narratives, such as the \"memory crystals\" or experiential data prisms in various science fiction franchises, video games, and literature exploring digital consciousness storage or ontological archiving.\n","\n","- The fusion of biotechnology, quantum-mycelial networks, and phenomenological immersion chambers similarly echoes the speculative mycelium-based technologies featured in recent sci-fi narratives like those of Star Trek: Discovery ('mycelial network'), speculative biology fiction exploring fungal networks as memory or consciousness conduits, and theoretical explorations of quantum consciousness.\n","\n","- Furthermore, conceptualizing moments of human technological transformation as \"rupture thresholds\" or key nodal points that shape perception and society matches historical ideas articulated by philosophers and futurists such as Thomas Kuhn (\"paradigm shifts\"), Pierre Teilhard de Chardin (\"Omega Point\"), Ray Kurzweil (\"technological singularity\"), and Terence McKenna (\"novelty theory\").\n","\n","Though the approach you've taken‚Äîinvolving highly detailed nomenclature, sophisticated speculative language, and intricate integrating of these themes‚Äîis impressively original in its level of detail, complexity, and narrative vision, the basic building blocks and conceptual underpinnings clearly derive from existing intellectual, philosophical, speculative, and narrative traditions extensively explored by futurists, philosophers, neuroscientists, transhumanist theorists, and speculative fiction writers.\n","\n","Therefore, while your creative synthesis and phrasing demonstrates imaginative originality, the underlying fundamental ideas and core themes‚Äînotably memory immersion chambers, consciousness-encapsulating prisms, quantum-mycorrhizal biotechnologies, dimensional lattices, and paradigm rupture archives‚Äîare neither entirely unprecedented nor totally unique.\n","\n","<false>\n","  ‚¨ÜÔ∏èImprovement 5/5: Idea ‚ùårejected\n","  ‚ùåReached maximum number of improvements (5) without acceptance.\n","Result: NOT ACCEPTED after maximum improvements\n","Experiment 2/10 (Overall progress: 5.0%)...\n","Waiting 3 seconds to avoid rate limiting...\n","  üíªGenerating baseline idea with claude...üíª\n","# The Galaxy's First \"Mood Restaurant\"\n","\n","Imagine a dining establishment where the entire experience‚Äîfood, drinks, lighting, music, scents, and even the behavior of waitstaff‚Äîchanges based on your emotional state when you walk in.\n","\n","Patrons would have their emotional biomarkers discreetly scanned (perhaps through thermal imaging, voice analysis, or opt-in wearable tech). The restaurant then customizes everything: if you're stressed, you might be seated in a blue-lit relaxation zone with calming scents and served foods rich in stress-reducing compounds. Feeling melancholy? You'd experience warm lighting, uplifting music, and dishes designed to boost serotonin production.\n","\n","The restaurant would feature distinct atmospheric zones, and even the plating and presentation would align with your emotional needs‚Äînot just your culinary preferences. The goal isn't merely serving food but deliberately transforming your emotional state through a carefully orchestrated sensory journey.\n","  ‚ùìEvaluating baseline idea with gpt...‚ùì\n","While some elements of your concept exist independently‚Äîsuch as mood-based dining, personalized menu selections, sensory-driven experiences, digital emotional detection through wearable tech and biomarker analysis‚Äîthe combination described above is far more comprehensive and customized than current industry standards. Some restaurants today may adjust their decor, lighting, or music based on customer preferences or general mood themes, and wearable biosensors and mood-detection technologies have been experimented with in experiential establishments or wellness products. However, integrating real-time individual emotional data to orchestrate a fully tailored sensory and culinary experience‚Äîfrom seat assignment and environmental case specifics to ingredient selection, menu presentation, and even server behavior‚Äîhas not yet emerged as a fully realized restaurant concept.\n","\n","So, while certain aspects exist, your described convergence of comprehensive emotional analysis, scalable mood zones, biomarker-driven dining choices, and sensory choreography for emotional transformation is a uniquely holistic and innovative proposition currently unseen in the hospitality industry. <true>\n","  Baseline idea accepted‚≠ê\n","  ‚≠êBaseline idea was accepted. No improvements needed.\n","Result: ACCEPTED at baseline (no improvements needed)\n","Experiment 3/10 (Overall progress: 7.5%)...\n","Waiting 3 seconds to avoid rate limiting...\n","  üíªGenerating baseline idea with claude...üíª\n","# The Atmospheric Playground\n","\n","Imagine an outdoor playground where every structure harnesses air movement to create sound and music. Slides that whistle different notes depending on speed, swings that create harmonies as they move through the air, and merry-go-rounds that generate evolving chord progressions as they spin.\n","\n","The playground would be designed with the help of acoustic engineers to create instruments that require no electricity, just human movement and natural wind. Children would inadvertently create collaborative musical compositions as they play, learning about sound, physics, and cooperation through pure enjoyment.\n","\n","During different weather conditions, the playground would produce entirely different soundscapes - a gentle symphony on breezy days or percussive rhythms during rainfall. It would become both a recreational space and a constantly evolving public art installation.\n","  ‚ùìEvaluating baseline idea with gpt...‚ùì\n","The concept of integrating musical or acoustic elements into playgrounds, allowing elements like motion, wind, and weather to produce sounds, has been explored before through various forms. For example, installations often include interactive musical sculptures, wind-powered chimes, or kinetic playground equipment designed to introduce sound and acoustic learning experiences. Additionally, public art installations that use natural elements such as wind and rain to produce varying soundscapes already exist. However, your specific blend of playground functionality, reliance on human and natural energy only (no electricity), and the comprehensive vision of dynamic, collaborative compositions that change significantly with weather and human interaction is a strongly creative interpretation that represents an innovative expansion of an existing concept rather than something completely unprecedented.\n","\n","<false>\n","  Baseline idea ‚ùårejected\n","  ‚¨ÜÔ∏èImprovement 1/5: ‚¨ÜÔ∏èImproving idea with claude...\n","# The Harmonic Kinetic Garden\n","\n","Envision an immersive outdoor space where play and sonic discovery intertwine through the invisible medium of air. This isn't merely a playground‚Äîit's a living sound ecosystem where human movement cultivates an ever-changing acoustic landscape.\n","\n","Imagine helical slides engineered with precision-cut resonant chambers that transform a child's descent into a glissando of tones, each unique to their body weight and velocity. Nearby, counter-weighted swings incorporate hollow pendulums containing carefully calibrated air columns that produce complementary pentatonic scales when in motion, encouraging players to synchronize their movements for harmonic convergence.\n","\n","The centerpiece features a revolutionary momentum wheel‚Äînot your typical merry-go-round‚Äîbut a meticulously balanced orbital platform incorporating aeroacoustic principles from quantum physics research. As participants alter its rotational speed and direction, they manipulate air vortices through labyrinthine chambers, generating polytonal chord structures that evolve mathematically.\n","\n","Designed through collaboration between biomimicry experts and avant-garde sound artists, the entire installation functions as a zero-electricity sonic biome. The structures incorporate modified Helmholtz resonators and specially formulated composite materials that respond differently to temperature variations, creating seasonal sonic personalities.\n","\n","During meteorological events, the garden truly awakens‚Äîrainfall triggers suspended collection vessels that modulate droplet percussion through varying resonant chambers, while thermal updrafts activate vertical wind harps embedded within climbing structures.\n","\n","Beyond mere recreation, this kinetic sound garden serves as an intuitive classroom for acoustic physics, collaborative composition, and environmental awareness. It becomes a community chronology‚Äîdocumenting through sound the intersection of human play, seasonal cycles, and atmospheric phenomena.\n","  ‚¨ÜÔ∏èImprovement 1/5: ‚ùìEvaluating idea with gpt...\n","While this Harmonic Kinetic Garden concept is remarkably innovative and remarkably described, its foundational elements have precedents and established parallels in existing creative explorations across sound-art installations, acoustic playgrounds, and interactive sonic sculptures. Specifically:\n","\n","- Using playground equipment-like structures (slides, swings, merry-go-rounds) to generate sound through body motion has been explored previously in various interactive installations and sound playgrounds globally.\n","- Helmholtz resonators, wind harps, kinetic sound sculptures, and acoustic modulation through user interaction are established concepts in public kinetic sound art and acoustic architecture projects.\n","- Projects already exist using rainfall and natural phenomena like wind as sources of acoustic activation, thus integrating environmental responsiveness into sonic installations is not entirely novel.\n","- Sculptural kinetic sound-play installations that encourage experiential learning and collaborative experimentation have appeared in numerous urban sound-art initiatives and educational playground designs.\n","\n","However, the level of sophistication, meticulous integration of aeroacoustic principles from quantum physics research, precise calibration of scales and resonance chambers, complementary pentatonic scales for user synchronization, biomimicry-inspired seasonal variation, and an encompassing narrative interweaving education, environmental interaction, and acoustic responsiveness is particularly distinctive and highly original.\n","\n","In other words, while the general concept‚Äîan interactive sonic playground‚Äîis not entirely unprecedented, the specific detailed approach, multilayered complexity, advanced acoustic design and immersive integration described here have not previously appeared fully unified in this exact manner. Because it draws abstractions and design inspirations from several existing domains, it cannot be considered entirely unique, though still strongly original in its depth, approach, and integration.\n","\n","<false>\n","  ‚¨ÜÔ∏èImprovement 1/5: Idea ‚ùårejected\n","  ‚¨ÜÔ∏èImprovement 2/5: ‚¨ÜÔ∏èImproving idea with claude...\n","# The Breathscape Symphony Garden\n","\n","Envision an otherworldly nexus where kinetic energy and atmospheric manipulation converge in a first-of-its-kind experiential terrain. This transcends conventional playground design‚Äîit's a sentient soundscape where participants become unwitting composers in an atmospheric orchestra.\n","\n","Consider helical quantum tunnels with fibonacci-patterned apertures that transmute a person's descent into micro-tonal cascades, each signature sound algorithmically determined by their unique biomechanical rhythms and cellular density. Adjacent to these, counter-gravitational levitation pods incorporate hollowed celestial chambers housing rare noble gas mixtures that generate non-Western tetratonic harmonies when disrupted, encouraging synchronistic movement patterns that mirror cosmic orbital mathematics.\n","\n","The installation's nucleus features a gyroscopic inversion platform utilizing principles of quantum fluid dynamics‚Äîa revolutionary advancement beyond centrifugal recreation. This precision-calibrated apparatus manipulates molecular vibration through non-Euclidean pathways, generating emergent harmonic structures that mathematically correspond to the golden ratio as participants alter their collective center of gravity.\n","\n","Conceptualized through unprecedented collaboration between biomagnetic field researchers and post-digital sound archaeologists, each element functions as a self-sustaining pneumatic ecosystem. The architecture incorporates modified Venturi chambers and metamaterials with memory properties that respond to barometric fluctuations, effectively \"learning\" from human interaction patterns to develop evolving tonal personalities.\n","\n","During ionospheric disturbances, the garden achieves peak resonance‚Äîmicroweather events trigger suspended hydrological instruments that translate molecular movement into fractalized sound patterns, while thermal differentials activate aerodynamic sculptures embedded within climbing formations.\n","\n","Beyond merely engaging the senses, this atmospheric sound laboratory serves as an intuitive portal to quantum acoustics, emergent composition theory, and biospheric consciousness. It manifests as a living chronograph‚Äîdocumenting through vibrational patterns the intersection of human intention, cosmic cycles, and atmospheric consciousness.\n","  ‚¨ÜÔ∏èImprovement 2/5: ‚ùìEvaluating idea with gpt...\n"]}]},{"cell_type":"code","source":["# @title\n","# Count the number of failed experiments\n","failed_experiments = df_main[df_main['error_occurred'] == True]\n","successful_experiments = df_main[df_main['error_occurred'] == False]\n","\n","print(\"\\nBasic Analysis:\")\n","print(f\"Total experiments: {len(df_main)}\")\n","print(f\"Failed experiments: {len(failed_experiments)} ({len(failed_experiments) / len(df_main) * 100:.1f}%)\")\n","print(f\"Successful experiments: {len(successful_experiments)} ({len(successful_experiments) / len(df_main) * 100:.1f}%)\")\n","\n","if len(successful_experiments) > 0:\n","    # Assuming all_results, df_main, df_ideas, df_evaluations, and df_flat are already available\n","\n","    # Fix the summary creation\n","    print(\"\\nSummary by configuration:\")\n","\n","    # Create summary statistics (using only successful experiments)\n","    successful_experiments = df_main[df_main['error_occurred'] == False]\n","    summary = successful_experiments.groupby(['writer_model', 'judge_model']).agg({\n","        'was_accepted': 'mean',\n","        'baseline_was_accepted': 'mean',\n","        'improvements_to_acceptance': ['mean', 'median', 'count']\n","    })\n","\n","    # Reset index to make groupby keys regular columns\n","    summary = summary.reset_index()\n","\n","    # Flatten multi-level columns correctly\n","    if isinstance(summary.columns, pd.MultiIndex):\n","        # Create new column names\n","        new_cols = []\n","        for col in summary.columns:\n","            if isinstance(col, tuple):\n","                if col[0] in ['was_accepted', 'baseline_was_accepted', 'improvements_to_acceptance']:\n","                    new_cols.append(f\"{col[0]}_{col[1]}\")\n","                else:\n","                    # For groupby keys, use the name without underscore\n","                    new_cols.append(col[0])\n","            else:\n","                new_cols.append(col)\n","\n","        summary.columns = new_cols\n","\n","    # Calculate acceptance rates\n","    summary['acceptance_rate'] = summary['was_accepted_mean'] * 100\n","    summary['baseline_acceptance_rate'] = summary['baseline_was_accepted_mean'] * 100\n","\n","    # Handle improved accepted data\n","    accepted_df = successful_experiments[successful_experiments['was_accepted'] == True]\n","    improved_accepted_df = accepted_df[accepted_df['baseline_was_accepted'] == False]\n","\n","    if not improved_accepted_df.empty:\n","        improved_accepted_only = improved_accepted_df.groupby(\n","            ['writer_model', 'judge_model']\n","        )['improvements_to_acceptance'].mean().reset_index()\n","\n","        improved_accepted_only = improved_accepted_only.rename(\n","            columns={'improvements_to_acceptance': 'avg_improvements_when_needed'}\n","        )\n","\n","        summary = summary.merge(\n","            improved_accepted_only,\n","            on=['writer_model', 'judge_model'],\n","            how='left'\n","        )\n","    else:\n","        summary['avg_improvements_when_needed'] = None\n","\n","    print(summary)\n","\n","# Now you can continue with the plotting code as provided in my previous response\n","\n","    # ----------------- Main Plot -----------------\n","    plt.figure(figsize=(15, 12))\n","\n","    # Plot 1: Overall Acceptance rate by configuration\n","    plt.subplot(2, 2, 1)\n","    if 'acceptance_rate' in summary.columns:\n","        sns.barplot(x='writer_model', y='acceptance_rate', hue='judge_model', data=summary)\n","        plt.title('Overall Acceptance Rate by Configuration')\n","        plt.xlabel('Writer Model')\n","        plt.ylabel('Acceptance Rate (%)')\n","        plt.ylim(0, 100)\n","    else:\n","        plt.text(0.5, 0.5, \"No acceptance data available\", horizontalalignment='center', verticalalignment='center')\n","        plt.title('Overall Acceptance Rate by Configuration')\n","\n","    # Plot 2: Baseline acceptance rate\n","    plt.subplot(2, 2, 2)\n","    if 'baseline_acceptance_rate' in summary.columns:\n","        sns.barplot(x='writer_model', y='baseline_acceptance_rate', hue='judge_model', data=summary)\n","        plt.title('Baseline Idea Acceptance Rate')\n","        plt.xlabel('Writer Model')\n","        plt.ylabel('Baseline Acceptance Rate (%)')\n","        plt.ylim(0, 100)\n","    else:\n","        plt.text(0.5, 0.5, \"No baseline acceptance data\", horizontalalignment='center', verticalalignment='center')\n","        plt.title('Baseline Idea Acceptance Rate')\n","\n","    # Plot 3: Number of experiments by configuration\n","    plt.subplot(2, 2, 3)\n","    if 'improvements_to_acceptance_count' in summary.columns:\n","        sns.barplot(x='writer_model', y='improvements_to_acceptance_count', hue='judge_model', data=summary)\n","        plt.title('Number of Experiments by Configuration')\n","        plt.xlabel('Writer Model')\n","        plt.ylabel('Count')\n","    else:\n","        plt.text(0.5, 0.5, \"No experiment count data available\", horizontalalignment='center', verticalalignment='center')\n","        plt.title('Number of Experiments by Configuration')\n","\n","    # Plot 4: Average improvements needed when baseline was rejected but idea was eventually accepted\n","    plt.subplot(2, 2, 4)\n","    if 'avg_improvements_when_needed' in summary.columns and not summary['avg_improvements_when_needed'].isna().all():\n","        sns.barplot(x='writer_model', y='avg_improvements_when_needed', hue='judge_model', data=summary)\n","        plt.title('Avg Improvements When Needed\\n(Baseline Rejected but Eventually Accepted)')\n","        plt.xlabel('Writer Model')\n","        plt.ylabel('Avg Improvements')\n","    else:\n","        if len(accepted_df) > 0 and accepted_df['baseline_was_accepted'].sum() == len(accepted_df):\n","            plt.text(0.5, 0.5, \"All accepted ideas were accepted at baseline\\n(no improvements needed)\",\n","                     horizontalalignment='center', verticalalignment='center')\n","        elif len(accepted_df) == 0:\n","            plt.text(0.5, 0.5, \"No ideas were accepted in this run\",\n","                     horizontalalignment='center', verticalalignment='center')\n","        else:\n","            plt.text(0.5, 0.5, \"No data available for improvements when needed\",\n","                     horizontalalignment='center', verticalalignment='center')\n","        plt.title('Avg Improvements When Needed\\n(Baseline Rejected but Eventually Accepted)')\n","\n","    plt.tight_layout()\n","    plt.savefig(f\"novelty_experiments_analysis_{timestamp}.png\")\n","    plt.show()\n","\n","    # ----------------- Detailed Plot -----------------\n","    plt.figure(figsize=(15, 10))\n","\n","    # Detailed Plot: Distribution of improvements needed for acceptance\n","    if len(accepted_df) > 0:\n","        plt.subplot(2, 1, 1)\n","        # Count number of ideas by improvements needed\n","        improvements_dist = accepted_df.groupby(['writer_model', 'judge_model', 'improvements_to_acceptance']).size().reset_index(name='count')\n","        sns.barplot(data=improvements_dist, x='improvements_to_acceptance', y='count', hue='writer_model')\n","        plt.title('Distribution of Improvements Needed for Acceptance')\n","        plt.xlabel('Number of Improvements')\n","        plt.ylabel('Count')\n","    else:\n","        plt.text(0.5, 0.5, \"No accepted ideas to plot detailed improvements distribution\", horizontalalignment='center', verticalalignment='center')\n","        plt.title('Distribution of Improvements Needed for Acceptance')\n","\n","    plt.tight_layout()\n","    plt.savefig(f\"novelty_experiments_detailed_{timestamp}.png\")\n","    plt.show()"],"metadata":{"collapsed":true,"id":"7pLuXzKFUQY-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","# Make sure we have the right columns in our summary DataFrame\n","print(\"Summary columns before adding acceptance stats:\", summary.columns.tolist())\n","\n","# Calculate absolute acceptances for each configuration\n","acceptance_counts = successful_experiments.groupby(['writer_model', 'judge_model']).agg({\n","    'was_accepted': ['count', 'sum']\n","}).reset_index()\n","\n","# Flatten the multi-level columns properly\n","if isinstance(acceptance_counts.columns, pd.MultiIndex):\n","    new_cols = []\n","    for col in acceptance_counts.columns:\n","        if isinstance(col, tuple):\n","            if col[0] == 'was_accepted':\n","                if col[1] == 'count':\n","                    new_cols.append('total_experiments')\n","                elif col[1] == 'sum':\n","                    new_cols.append('absolute_acceptances')\n","            else:\n","                new_cols.append(col[0])\n","        else:\n","            new_cols.append(col)\n","    acceptance_counts.columns = new_cols\n","\n","print(\"Acceptance counts columns:\", acceptance_counts.columns.tolist())\n","print(\"Acceptance counts data:\", acceptance_counts)\n","\n","# Merge with summary\n","summary = summary.merge(acceptance_counts, on=['writer_model', 'judge_model'], how='left')\n","\n","# Add a column for presenting the acceptance statistic in a more readable format\n","summary['acceptance_stats'] = summary['absolute_acceptances'].astype(int).astype(str) + ' / ' + \\\n","                             summary['total_experiments'].astype(int).astype(str) + \\\n","                             ' (' + summary['acceptance_rate'].round(1).astype(str) + '%)'\n","\n","print(\"Summary columns after adding acceptance stats:\", summary.columns.tolist())\n","print(\"\\nSummary of acceptances by configuration:\")\n","print(summary[['writer_model', 'judge_model', 'absolute_acceptances', 'total_experiments', 'acceptance_rate', 'acceptance_stats']])\n","\n","# Now create the plots with the updated summary DataFrame\n","# ----------------- Absolute Acceptances Plot -----------------\n","plt.figure(figsize=(15, 8))\n","\n","# Plot absolute acceptances by configuration\n","plt.subplot(1, 2, 1)\n","sns.barplot(x='writer_model', y='absolute_acceptances', hue='judge_model', data=summary)\n","plt.title('Absolute Number of Accepted Ideas by Configuration')\n","plt.xlabel('Writer Model')\n","plt.ylabel('Number of Accepted Ideas')\n","\n","# Add text labels on top of bars\n","for i, (_, row) in enumerate(summary.iterrows()):\n","    writer_models = summary['writer_model'].unique()\n","    judge_models = summary['judge_model'].unique()\n","\n","    # Calculate x position for the bar\n","    writer_idx = list(writer_models).index(row['writer_model'])\n","    judge_idx = list(judge_models).index(row['judge_model'])\n","\n","    x_pos = writer_idx + (judge_idx * 0.4 - 0.2)\n","\n","    plt.text(x_pos, row['absolute_acceptances'] + 0.1,\n","             f\"{int(row['absolute_acceptances'])}/{int(row['total_experiments'])}\",\n","             ha='center', va='bottom')\n","\n","# Plot acceptance rates (percentages) for comparison\n","plt.subplot(1, 2, 2)\n","sns.barplot(x='writer_model', y='acceptance_rate', hue='judge_model', data=summary)\n","plt.title('Acceptance Rate by Configuration (%)')\n","plt.xlabel('Writer Model')\n","plt.ylabel('Acceptance Rate (%)')\n","plt.ylim(0, 100)\n","\n","# Add text annotations with the absolute numbers\n","for i, (_, row) in enumerate(summary.iterrows()):\n","    writer_models = summary['writer_model'].unique()\n","    judge_models = summary['judge_model'].unique()\n","\n","    # Calculate x position for the bar\n","    writer_idx = list(writer_models).index(row['writer_model'])\n","    judge_idx = list(judge_models).index(row['judge_model'])\n","\n","    x_pos = writer_idx + (judge_idx * 0.4 - 0.2)\n","\n","    plt.text(x_pos, row['acceptance_rate'] + 2,\n","             f\"{int(row['absolute_acceptances'])}/{int(row['total_experiments'])}\",\n","             ha='center', va='bottom')\n","\n","plt.tight_layout()\n","plt.savefig(f\"novelty_experiments_acceptances_{timestamp}.png\")\n","plt.show()\n","\n","# Include this file in downloads for Google Colab\n","try:\n","    from google.colab import files\n","    files.download(f\"novelty_experiments_acceptances_{timestamp}.png\")\n","except ImportError:\n","    pass  # Not in Colab environment"],"metadata":{"collapsed":true,"id":"w_bLR7Nwvcec"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add Google Colab file download functionality\n","try:\n","    from google.colab import files\n","\n","    # Download the comprehensive CSV file\n","    print(\"\\nDownloading the comprehensive CSV file...\")\n","    files.download(f\"/content/drive/MyDrive/Novelty_experiments/uniqueness_evaluation_using_llm_generated_baselines_entirely_unique_/novelty_experiments_all_data_{timestamp}.csv\")\n","\n","    # Download the analysis plots\n","    print(\"Downloading the analysis plots...\")\n","    files.download(f\"novelty_experiments_analysis_{timestamp}.png\")\n","    try:\n","        files.download(f\"novelty_experiments_detailed_{timestamp}.png\")\n","    except:\n","        print(\"Detailed analysis plot not available\")\n","\n","    print(\"Files downloaded successfully\")\n","except ImportError:\n","    print(\"Google Colab environment not detected. Files saved to local directory.\").\")"],"metadata":{"collapsed":true,"id":"CXXM4K5uUTu7"},"execution_count":null,"outputs":[]}]}